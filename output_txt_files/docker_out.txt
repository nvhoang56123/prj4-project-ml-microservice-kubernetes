<paste log output from Docker prediction, here>
[Make Prediction After Docker Run]
[hoangnv5@cos-262795445 prj4-project-ml-microservice-kubernetes]$ ./make_prediction.sh
Port: 8000
{
  "prediction": [
    20.35373177134412
  ]
}

[GET ContainerID]
[hoangnv5@cos-262795445 prj4-project-ml-microservice-kubernetes]$ sudo docker container ls
CONTAINER ID   IMAGE                                           COMMAND           CREATED          STATUS         PORTS                  NAMES
369414d58ff5   prj4-project-ml-microservice-kubernetes:1.0.0   "python app.py"   10 seconds ago   Up 8 seconds   0.0.0.0:8000->80/tcp   objective_shtern

[Check Logs]
[hoangnv5@cos-262795445 prj4-project-ml-microservice-kubernetes]$ sudo docker container logs 369414d58ff5
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 993-164-040
[2023-06-16 21:55:17,230] INFO in app: JSON payload:
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2023-06-16 21:55:17,263] INFO in app: Inference payload DataFrame:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2023-06-16 21:55:17,288] INFO in app: Scaling Payload:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2023-06-16 21:55:17,299] INFO in app: the scaled input: [[0. 0. 0. 0. 0. 0.]]
[2023-06-16 21:55:17,302] INFO in app: The resultant prediction: [20.35373177134412]
172.17.0.1 - - [16/Jun/2023 21:55:17] "POST /predict HTTP/1.1" 200 -